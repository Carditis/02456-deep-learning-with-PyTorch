{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bu1Wy6Xb81Sn"
   },
   "source": [
    "# Credits\n",
    "\n",
    "This is heavily influenced from https://github.com/pytorch/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZW0gaQO81Sq"
   },
   "source": [
    "# CIFAR-10\n",
    "\n",
    "In this notebook you need to put what you have learned into practice, and create your own convolutional classifier for the CIFAR-10 dataset.\n",
    "\n",
    "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’.\n",
    "The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    "![cifar10](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/static_files/cifar10.png?raw=1)\n",
    "\n",
    "\n",
    "In order to train a classifier the following steps needs to be performed:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "We will help you along the way.\n",
    "We indicate the places you need to modify the code with `# Your code here!`.\n",
    "It is however a good idea to read the entire assignment before you begin coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htyg7xxN81St"
   },
   "source": [
    "## 1. Loading and normalizing CIFAR10\n",
    "\n",
    "Using ``torchvision``, it’s extremely easy to load CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3u2GIWr81Su"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xx5SHRkm81S0"
   },
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1]\n",
    "\n",
    "**NB** Modify the code below to only use a small part of the dataset if your computer is very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "QZeTujLC81S3",
    "outputId": "656d4f5a-d1cc-4aa8-9fa6-94ac83d6c12e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "used classes: ['cat', 'dog']\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "used_categories = range(len(classes))\n",
    "\n",
    "## USE CODE BELOW IF YOUR COMPUTER IS TOO SLOW\n",
    "reduce_dataset = True\n",
    "if reduce_dataset:\n",
    "    used_categories = (3, 5) # cats and dogs\n",
    "\n",
    "    classes = [classes[i] for i in used_categories]\n",
    "    new_train_data = []\n",
    "    new_train_labels = []\n",
    "\n",
    "    new_test_data = []\n",
    "    new_test_labels = []\n",
    "    for i, t in enumerate(used_categories):\n",
    "        new_train_data.append(trainset.data[np.where(np.array(trainset.targets) == t)])\n",
    "        new_train_labels += [i for _ in range(new_train_data[-1].shape[0])]\n",
    "\n",
    "        new_test_data.append(testset.data[np.where(np.array(testset.targets) == t)])\n",
    "        new_test_labels += [i for _ in range(new_test_data[-1].shape[0])]\n",
    "\n",
    "    new_train_data = np.concatenate(new_train_data, 0)\n",
    "    trainset.data = new_train_data\n",
    "    trainset.targets = new_train_labels\n",
    "\n",
    "    new_test_data = np.concatenate(new_test_data, 0)\n",
    "    testset.data = new_test_data\n",
    "    testset.targets = new_test_labels\n",
    "\n",
    "    \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "train_data_iter = iter(trainloader)\n",
    "test_data_iter = iter(testloader)\n",
    "print('used classes:', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "JDHkc52L81S9",
    "outputId": "d06106f2-f6b5-46be-9b46-07637861aa8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Training data\n",
      "Number of points: 10000\n",
      "Batch dimension [B x C x H x W]: torch.Size([4, 3, 32, 32])\n",
      "Number of distinct labels: 2\n",
      "\n",
      "# Test data\n",
      "Number of points: 2000\n",
      "Batch dimension [B x C x H x W]: torch.Size([4, 3, 32, 32])\n",
      "Number of distinct labels: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"# Training data\")\n",
    "print(\"Number of points:\", len(trainset))\n",
    "x, y = next(iter(trainloader))\n",
    "print(\"Batch dimension [B x C x H x W]:\", x.shape)\n",
    "print(\"Number of distinct labels:\", len(set(trainset.targets)))\n",
    "\n",
    "\n",
    "print(\"\\n# Test data\")\n",
    "print(\"Number of points:\", len(testset))\n",
    "x, y = next(iter(testloader))\n",
    "print(\"Batch dimension [B x C x H x W]:\", x.shape)\n",
    "print(\"Number of distinct labels:\", len(set(testset.targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x00000218B1E34880>\n"
     ]
    }
   ],
   "source": [
    "print(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSA1h94681TB"
   },
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "njJy0klP81TD",
    "outputId": "693811f4-a8c1-41ce-d885-b3fbbaca8b46"
   },
   "outputs": [],
   "source": [
    "# Run this cell multiple time to see more samples\n",
    "\n",
    "#KERNEL DIES WHEN I TRY TO RUN IT\n",
    "\n",
    "#def imshow(img):\n",
    "#    \"\"\" show an image \"\"\"\n",
    "#    img = img / 2 + 0.5 # unnormalize\n",
    "#    npimg = img.numpy()\n",
    "#    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "#images, labels = train_data_iter.next()\n",
    "\n",
    "# show images\n",
    "#imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "#print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wt3BVFMF81TI"
   },
   "source": [
    "## 2. Define a Convolutional Neural Network\n",
    "\n",
    "**Assignment 1:** Define a convolutional neural network. \n",
    "You may use the code from previous notebooks.\n",
    "We suggest that you start with a small network, and make sure that everything is working.\n",
    "Once you can train successfully come back and improve the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_EsKbw3o81TK",
    "outputId": "aad251c1-367f-4256-b96d-15d319048482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv_1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (linear_1): Linear(in_features=12544, out_features=100, bias=True)\n",
      "  (l_out): Linear(in_features=100, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "channels = x.shape[1]\n",
    "height = x.shape[2]\n",
    "width = x.shape[3]\n",
    "num_filters_conv1 = 16\n",
    "kernel_size_conv1 = 5 # [height, width]\n",
    "stride_conv1 = 1 # [stride_height, stride_width]\n",
    "num_l1 = 100\n",
    "padding_conv1 = 0\n",
    "   \n",
    "def compute_conv_dim(dim_size):\n",
    "    return int((dim_size - kernel_size_conv1 + 2 * padding_conv1) / stride_conv1 + 1)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.conv_out_height = compute_conv_dim(height)\n",
    "        self.conv_out_width = compute_conv_dim(width)\n",
    "        \n",
    "        self.l1_in_features = num_filters_conv1 * self.conv_out_height * self.conv_out_width\n",
    "        \n",
    "        self.conv_1 = self.conv_1 = Conv2d(in_channels=channels,\n",
    "                             out_channels=num_filters_conv1,\n",
    "                             kernel_size=kernel_size_conv1,\n",
    "                             stride=stride_conv1, padding=padding_conv1)\n",
    "        \n",
    "        self.linear_1 = Linear(in_features=self.l1_in_features, \n",
    "                          out_features=num_l1,\n",
    "                          bias=True)\n",
    "        \n",
    "        self.l_out = Linear(in_features=num_l1, \n",
    "                            out_features=num_classes,\n",
    "                            bias=False)\n",
    "        \n",
    "        # Your code here!\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = relu(self.conv_1(x))\n",
    "        x = x.view(-1, self.l1_in_features)\n",
    "        x = relu(self.linear_1(x))\n",
    "        x = softmax(self.l_out(x))\n",
    "        \n",
    "        # Your code here!\n",
    "        return x\n",
    "    \n",
    "\n",
    "net = Net(len(used_categories))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7-IUg3sq81TQ"
   },
   "source": [
    "## 3. Define a Loss function and optimizer\n",
    "\n",
    "**Assignment 2:** Implement the criterion and optimizer. \n",
    "We suggest Classification Cross-Entropy loss and SGD with momentum.\n",
    "You might need to experiment a bit with the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48AX85QP81TR"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-WneIN7C81TV"
   },
   "source": [
    "## 4. Train the network\n",
    "\n",
    "**Assignment 3:** Finish the training loop below. \n",
    "Start by using a small number of epochs (e.g. 3).\n",
    "Even with a low number of epochs you should be able to see results that are better than chance.\n",
    "When everything is working increase the number of epochs to find out how good your network really is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NkUanRRb81TW"
   },
   "outputs": [],
   "source": [
    "num_epoch = 3  # Your code here!\n",
    "\n",
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        # Your code here!\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        # Your code here!\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0qAsbC8I81Ta"
   },
   "source": [
    "## 5. Test the network on the test data\n",
    "\n",
    "Now we need to check if the network has learnt anything at all.\n",
    "We will check this by predicting the class label that the neural network outputs, and checking it against the ground truth.\n",
    "If the prediction is correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LT0RoAC81Tc"
   },
   "outputs": [],
   "source": [
    "images, labels = test_data_iter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "plt.show()\n",
    "\n",
    "print('GroundTruth:  ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "outputs = net(images)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print('Predicted:    ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISA6LJJO81Tg"
   },
   "source": [
    "Let us look at how the network performs on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Smv6_BwF81Ti"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the {} test images: {:4.2f} %'.format(\n",
    "    testset.data.shape[0], 100 * correct.true_divide(total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMZRvhaW81Tl"
   },
   "source": [
    "Hopefully the network is better than chance, which is $\\frac{1}{\\text{number of classes}}$ accuracy (randomly picking\n",
    "a class).\n",
    "\n",
    "\n",
    "We can also examine which class the network found the most difficult (makes more sense if you have many clases):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WqVTQgKq81Tl"
   },
   "outputs": [],
   "source": [
    "class_total = list(0. for i in range(len(classes)))\n",
    "class_correct = list(0. for i in range(len(classes)))\n",
    "\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    \n",
    "    for i in range(len(c)):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i].numpy()\n",
    "        class_total[label] += 1\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    print('Accuracy of {:5s} : {:5.2f} %'.format(\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocnQOBAl81Tn"
   },
   "source": [
    "**Assignment 4:** \n",
    "1. Go back and improve performance of the network. \n",
    " * If you are using all 10 classes you should get a test accuracy above 55%, but see how much further you can get it!\n",
    " * If you are using only 2 classes (e.g. cat and dog) you should get a test accuracy above 60%, but see how much further you can get it!\n",
    "\n",
    "2. Briefly describe what you did and any experiments you did along the way as well as what results you obtained.\n",
    "Did anything surprise you during the exercise?\n",
    "\n",
    "3. Write down key lessons/insights you got (if any) during this exercise.\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Nzefavy81To"
   },
   "source": [
    "# Training on GPU\n",
    "\n",
    "**Optional Assignment:**\n",
    "If you have a GPU we suggest that you try and rewrite the code above to run on the GPU\n",
    "___\n",
    "\n",
    "Just like how you transfer a Tensor on to the GPU, you transfer the neural net onto the GPU.\n",
    "This will recursively go over all modules and convert their parameters and buffers to CUDA tensors:\n",
    "\n",
    "```\n",
    "    net.cuda()\n",
    "```\n",
    "\n",
    "Remember that you will have to send the inputs and targets at every step to the GPU too:\n",
    "\n",
    "```\n",
    "    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "```\n",
    "\n",
    "Why dont I notice MASSIVE speedup compared to CPU? \n",
    "Because your network is realllly small.\n",
    "\n",
    "**Exercise:** Try increasing the width of your network (argument 2 of\n",
    "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` –\n",
    "they need to be the same number), see what kind of speedup you get.\n",
    "\n",
    "**Goals achieved**:\n",
    "\n",
    "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
    "- Train a small neural network to classify images\n",
    "\n",
    "## Setting up GPU in Colab\n",
    "\n",
    "In Colab, you will get 12 hours of execution time but the session will be disconnected if you are idle for more than 60 minutes. It means that for every 12 hours Disk, RAM, CPU Cache and the Data that is on our allocated virtual machine will get erased.\n",
    "\n",
    "To enable GPU hardware accelerator, just go to **Runtime -> Change runtime type -> Hardware accelerator -> GPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b8mEIylU81Tp"
   },
   "source": [
    "# Michael Nielsen book exercise of own choice\n",
    "\n",
    "**Assignment 5:** Pick an exercise of own choice from [Michael Nielsens book](http://neuralnetworksanddeeplearning.com/)\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of 4.3-EXE-CIFAR-10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
