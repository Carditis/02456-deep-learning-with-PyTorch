{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 5 - Deep learning with Transformers\n",
    "Some preliminary set-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ipywidgets rich seaborn torch datasets transformers tokenizers sentencepiece sacremoses --quiet\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import rich\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import transformers\n",
    "import tokenizers\n",
    "import datasets\n",
    "import zipfile\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# define the device to use\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "rich.print(f\"Device: [red]{DEVICE}\")\n",
    "\n",
    "# control verbosity\n",
    "transformers.logging.set_verbosity_error()\n",
    "datasets.logging.set_verbosity_error()\n",
    "\n",
    "# define support functions\n",
    "def load_glove_vectors(filename = \"glove.6B.300d.txt\") -> Tuple[List[str], torch.Tensor]:\n",
    "    \"\"\"Load the GloVe vectors. See: `https://github.com/stanfordnlp/GloVe`\"\"\"\n",
    "    path = Path(hf_hub_download(repo_id=\"stanfordnlp/glove\", filename=\"glove.6B.zip\"))\n",
    "    target_file = path.parent / filename\n",
    "    if not target_file.exists():\n",
    "        with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(path.parent)\n",
    "\n",
    "        if not target_file.exists():\n",
    "            print(f\"Available files:\")\n",
    "            for p in path.parent.iterdir():\n",
    "                print(p)\n",
    "            raise ValueError(f\"Target file `{target_file.name}` can't be found. Check if `{filename}` was properly downloaded.\")\n",
    "\n",
    "    # parse the vocabulary and the vectors\n",
    "    vocabulary = []\n",
    "    vectors = []\n",
    "    with open(target_file, \"r\") as f:\n",
    "        for l in tqdm(f.readlines(), desc=f\"Parsing {target_file.name}...\" ):\n",
    "            word, *vector = l.split()\n",
    "            vocabulary.append(word)\n",
    "            vectors.append(torch.tensor([float(v) for v in vector]))\n",
    "    vectors = torch.stack(vectors)\n",
    "    return vocabulary, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for the later cells\n",
    "glove_vocabulary, glove_vectors = load_glove_vectors()\n",
    "rich.print(f\"glove_vocabulary: type={type(glove_vocabulary)}, length={len(glove_vocabulary)}\")\n",
    "rich.print(f\"glove_vectors: type={type(glove_vectors)}, shape={glove_vectors.shape}, dtype={glove_vectors.dtype}\")\n",
    "\n",
    "# add special tokens\n",
    "special_tokens = ['<|start|>', '<|unknown|>', '<|pad|>']\n",
    "glove_vocabulary = special_tokens + glove_vocabulary\n",
    "glove_vectors = torch.cat([torch.randn_like(glove_vectors[:len(special_tokens)]), glove_vectors])\n",
    "\n",
    "# tokenizer for GloVe\n",
    "glove_tokenizer = tokenizers.Tokenizer(tokenizers.models.WordLevel(vocab={v:i for i,v in enumerate(glove_vocabulary)}, unk_token=\"<|unknown|>\"))\n",
    "glove_tokenizer.normalizer = tokenizers.normalizers.BertNormalizer(strip_accents=False)\n",
    "glove_tokenizer.pre_tokenizer = tokenizers.pre_tokenizers.Whitespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Language Modelling and Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
